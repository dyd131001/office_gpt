{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj20obAAIH6P",
        "outputId": "83a5b8b7-cc69-4a70-c335-1fc2d26c083e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRetrieving Grit CLI metadata from https://api.keygen.sh/v1/accounts/custodian-dev/artifacts/marzano-linux-x64\n",
            "\n",
            "\u001b[1m\u001b[2mAnalyzing\u001b[0m \u001b[1m\u001b[2m                                                                      \u001b[0m\n",
            "\u001b[2K\u001b[2A\n",
            "\u001b[1m\u001b[2mAnalyzing\u001b[0m \u001b[1m\u001b[2m                                                                      \u001b[0m\n",
            "\u001b[2K\u001b[2A\n",
            "\u001b[1m\u001b[2mAnalyzing\u001b[0m \u001b[1m\u001b[2m                                                                      \u001b[0m\n",
            "\u001b[2K\u001b[2AProcessed 0 files and found 0 matches\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.11.17)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=a2d1da79f115a629e420712f231910f2390f74716aa29d5db1af53807f81df32\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.2\n",
            "    Uninstalling httpcore-1.0.2:\n",
            "      Successfully uninstalled httpcore-1.0.2\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.25.2\n",
            "    Uninstalling httpx-0.25.2:\n",
            "      Successfully uninstalled httpx-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "openai 1.3.7 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting Faker\n",
            "  Downloading Faker-20.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from Faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n",
            "Downloading Faker-20.1.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Faker\n",
            "Successfully installed Faker-20.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install openai --upgrade\n",
        "!openai migrate\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install Faker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y49_M0ddJW3F"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "def mk_File(file_name, file_content, path):\n",
        "    # 파일 경로와 이름을 지정합니다.\n",
        "    file_path = \"/Users/bagjeong-yong/Desktop/gpt\"\n",
        "\n",
        "    # 파일이 이미 존재하면 삭제합니다.\n",
        "    if os.path.exists(os.path.join(file_path, file_name)):\n",
        "        os.remove(os.path.join(file_path, file_name))\n",
        "\n",
        "    # 파일 디렉토리가 존재하지 않으면 생성합니다.\n",
        "    if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "    # 파일 객체를 생성합니다.\n",
        "    with open(os.path.join(file_path, file_name), \"w\") as f:\n",
        "        # 파일에 내용을 작성합니다.\n",
        "        f.write(file_content)\n",
        "\n",
        "    print(f\"{os.path.join(file_path, file_name)} 파일이 생성되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8CnqguCl51G",
        "outputId": "5da36cdb-c424-411d-d1ca-1ccba98150e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
            "Collecting httpx\n",
            "  Using cached httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Collecting httpcore\n",
            "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2023.11.17)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (2.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (1.2.0)\n",
            "Using cached httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "Installing collected packages: h11, httpcore, httpx\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.9.0\n",
            "    Uninstalling h11-0.9.0:\n",
            "      Successfully uninstalled h11-0.9.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 0.9.1\n",
            "    Uninstalling httpcore-0.9.1:\n",
            "      Successfully uninstalled httpcore-0.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.13.3\n",
            "    Uninstalling httpx-0.13.3:\n",
            "      Successfully uninstalled httpx-0.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "googletrans 4.0.0rc1 requires httpx==0.13.3, but you have httpx 0.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade httpx httpcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s3kOEWIoIXtq"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "def code_file():\n",
        "    ti, lang = input(\"파일 이름 with 파일 유형(.py, .c, .cpp ...etc) \\n\").split(\".\")\n",
        "    content = input(\"만드려는 코드 내용(30자 이내) : \")\n",
        "    client = OpenAI(api_key=\"\", )\n",
        "\n",
        "    response = client.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": content + \" as .\" + lang}\n",
        "        ],\n",
        "        temperature=0,\n",
        "        max_tokens=100,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0.0,\n",
        "        presence_penalty=0.0\n",
        "    )\n",
        "\n",
        "    fc = response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "\n",
        "    path = \"/Users/bagjeong-yong/Desktop/gpt\"\n",
        "    mk_File(ti +\".\"+ lang, fc, path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZa1S0a1mBvF",
        "outputId": "46ca0f28-6fd5-42f4-cb77-ff90f55dd941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mtranslate\n",
            "  Downloading mtranslate-1.8.tar.gz (2.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mtranslate\n",
            "  Building wheel for mtranslate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mtranslate: filename=mtranslate-1.8-py3-none-any.whl size=3672 sha256=cc2155e81826aff441fd1ca4ca4b12868e72a948b8f8787717ad6645af3e0be1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/04/15/d7654c2c4a9a52e09922967593f3278fed66059be65ca671ea\n",
            "Successfully built mtranslate\n",
            "Installing collected packages: mtranslate\n",
            "Successfully installed mtranslate-1.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install mtranslate\n",
        "from mtranslate import translate\n",
        "\n",
        "# 한글을 판별합니다.\n",
        "def is_korean(word):\n",
        "    for char in word:\n",
        "        if '가' <= char <= '힣':\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def e_translate(k_word):\n",
        "    # 라이브러리를 사용하여 번역합니다.\n",
        "    if is_korean(k_word):\n",
        "        outStr = translate(k_word, 'en')\n",
        "        return outStr\n",
        "    else:\n",
        "        return k_word\n",
        "\n",
        "def k_translate(e_word):\n",
        "    # 라이브러리를 사용하여 번역합니다.\n",
        "    outStr = translate(e_word, 'ko')\n",
        "    return outStr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fKHIzBxUsPBx"
      },
      "outputs": [],
      "source": [
        "# 필요한 모듈을 import 합니다.\n",
        "import json\n",
        "\n",
        "def word_file():\n",
        "  client = OpenAI(api_key=\"\", )\n",
        "\n",
        "  # 파일 내용을 Openai를 이용해 생성합니다.\n",
        "  ti, lang = input(\"파일 이름 with 파일 유형(.docx, .hwp, ...etc) \\n\").split(\".\")\n",
        "  role = e_translate(input(\"주제 분야 (과학, 인문 ..etc): \"))\n",
        "  title = e_translate(input(\"파일 목적( ex 과학혁명의 구조 보고서): \"))\n",
        "  topic = e_translate(input(\"들어가야할 내용 (동기, 줄거리 , 결론 .. etc): \"))\n",
        "\n",
        "  # 모델 엔진을 지정합니다.\n",
        "  model = \"gpt-3.5-turbo\"\n",
        "  # 생성할 최대 토큰 수를 지정합니다.\n",
        "  max_tokens = 1024\n",
        "  # 생성된 텍스트의 창의성과 예측 가능성을 조절합니다.\n",
        "  temperature = 0.5\n",
        "\n",
        "\n",
        "  prompt = f\"I'm in in the field of {role}. I'm going to write {title}. Write a report using according to {topic}\"\n",
        "\n",
        "  response = client.completions.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "      {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ]\n",
        "  )\n",
        "\n",
        "  fc = k_translate(response.choices[0].text)\n",
        "  print(fc)\n",
        "  path = \"/Users/bagjeong-yong/Desktop/gpt\"\n",
        "  mk_File(ti +\".\"+ lang, fc, path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_ZCd-Zc50NVG"
      },
      "outputs": [],
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "def generate_data(cols, n):\n",
        "\n",
        "    fake = Faker('ko_KR')\n",
        "\n",
        "    data = []\n",
        "    for i in range(n):\n",
        "        row = []\n",
        "        for j in range(len(cols)):\n",
        "            if str(cols[j]) == '1':\n",
        "                row.append(fake.name())\n",
        "            elif str(cols[j])== '2':\n",
        "                row.append(random.choice(['Active', 'Inactive']))\n",
        "            elif str(cols[j]) == '3':\n",
        "                row.append(fake.date_between(start_date='-1y', end_date='today')) #replace with random date\n",
        "            elif str(cols[j]) == '4':\n",
        "                row.append(fake.date_between(start_date='+1d', end_date='+1y'))\n",
        "            elif str(cols[j])== '5':\n",
        "                row.append('customer' + str(i) + '@example.com') #replace with random email\n",
        "            elif str(cols[j]) == '6':\n",
        "                row.append(random.randint(20, 60))\n",
        "            elif str(cols[j]) == '7':\n",
        "                row.append(random.choice(['A', 'B', 'C', 'D']))\n",
        "            elif str(cols[j]) == '8':\n",
        "                row.append(random.randint(10000, 50000))\n",
        "            elif str(cols[j]) == '9':\n",
        "                row.append(fake.phone_number())\n",
        "            elif str(cols[j]) == '10':\n",
        "                row.append(fake.address())\n",
        "            elif str(cols[j]) == '11':\n",
        "                row.append(i)\n",
        "            else:\n",
        "                row.append(\"null\")\n",
        "        data.append(row)\n",
        "    return data\n",
        "\n",
        "import string\n",
        "def col_num_to_str(col_num):\n",
        "    if col_num <= 0:\n",
        "        raise ValueError('열 번호는 1 이상이어야 합니다.')\n",
        "    col_str = ''\n",
        "    while col_num > 0:\n",
        "        remainder = (col_num - 1) % 26\n",
        "        col_str = string.ascii_uppercase[remainder] + col_str\n",
        "        col_num = (col_num - 1) // 26\n",
        "    return col_str\n",
        "\n",
        "\n",
        "# 필요한 모듈을 import 합니다.\n",
        "import os\n",
        "import json\n",
        "import ast\n",
        "import pandas as pd\n",
        "import openpyxl\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "def excel_file():\n",
        "\n",
        "  client = OpenAI(api_key=\"\", )\n",
        "\n",
        "  ti, lang = input(\"엑셀 제목 with 파일 유형(xlsx, ...etc) \\n\").split(\".\")\n",
        "  role = e_translate(input(\"주제 분야 (고객관리 ..etc): \"))\n",
        "  n_row = str(input(\"행 개수 : \"))\n",
        "  n_column = str(input(\"열 개수 : \"))\n",
        "\n",
        "  # 모델 엔진을 지정합니다.\n",
        "  model = \"gpt-3.5-turbo\"\n",
        "  # 생성할 최대 토큰 수를 지정합니다.\n",
        "  max_tokens = 500\n",
        "  # 생성된 텍스트의 창의성과 예측 가능성을 조절합니다.\n",
        "  temperature = 0.5\n",
        "\n",
        "  prompt = f\"You're a consultant. I'm trying to make a member management excel file with a size of {n_row} about {role}. Give me an example by wrapping up the contents of the line with \\\\\\ \"\n",
        "\n",
        "  response = client.completions.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "       ],\n",
        "       temperature=temperature,\n",
        "       max_tokens=max_tokens,\n",
        "       n=1,\n",
        "       stop=None\n",
        "    )\n",
        "\n",
        "  fc = response['choices'][0]['message']['content'].split(\"\\\\\")\n",
        "  new_list = [element.strip('').replace(\":\", '').replace(\" \", '').replace(\"\\n\", '') for element in fc if\n",
        "             element.strip()]\n",
        "  print(new_list)\n",
        "\n",
        "  ask_list = [\"?\" for i in range(int(n_row))]\n",
        "\n",
        "  prompt = f\"어떠한 행이 주어지면 행의 각 항목이 1(이름 - 3글자이하 문자반환), 2(시작날짜 - 끝날짜보다 작은 날짜 반환), 3(끝 - 시작날짜보다 큰 날짜 반환), 4(이메일 - 문자@ex.com 반환), 5(나이 - 20~50 사이의 수 반환), 6(활성상태 - 2가지 상태를 반환), 7(성적 - A~D 중 임의의 알파벳 반환) 8(가격- 10000~50000이하의 수 반환) 9(핸드폰 번호 - ###-####-### 반환),10(지역- 지역을 표시하는 문자열 반환) ,11(고객id - 고객별 고유번호 생성 ), 12(해당사항없음) 중 가장 연관성있는 번호를 찾고 그에따라 데이터를 생성하려고 해. {new_list} 에 각 항목들은 어떤 번호에 가장 가까울까? 답의 형식은 \\ {ask_list} \\ 이다..\"\n",
        "\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "      ],\n",
        "      temperature=temperature,\n",
        "      max_tokens=max_tokens,\n",
        "      n=1,\n",
        "      stop=None\n",
        "  )\n",
        "\n",
        "  result_list = ast.literal_eval(response.choices[0].text)\n",
        "  print(result_list)\n",
        "  matrix = generate_data(result_list,int(n_column))\n",
        "  print(matrix[0])\n",
        "  df = pd.DataFrame(matrix , columns=new_list)\n",
        "  print(df)\n",
        "  df.to_excel(ti +\".\"+ lang)\n",
        "\n",
        "  while True:\n",
        "    print(\"기능 : < 정렬, 합산, 평균, 최소, 최대 > 중 선택\")\n",
        "    func = input(\"원하는 기능입력( 형식 : 최대, 평균..) 추가를 원하지 않을 경우 q입력\")\n",
        "    if func == 'q':\n",
        "      break\n",
        "    t_col = col_num_to_str(int(input(f\"{func}값을 구하고 싶은 열 입력 (형식 : 2..)\")))\n",
        "    n_column = int(n_column)\n",
        "    if func == '정렬':\n",
        "        value = f'=SORT({t_col}1:{t_col}{n_column})'\n",
        "    elif func == '합산':\n",
        "        value = f'=SUM({t_col}1:{t_col}{n_column})'\n",
        "    elif func == '평균':\n",
        "        value = f'=AVERAGE({t_col}1:{t_col}{n_column})'\n",
        "    elif func == '최소':\n",
        "        value = f'=MIN({t_col}1:{t_col}{n_column})'\n",
        "    elif func == '최대':\n",
        "        value = f'=MAX({t_col}1:{t_col}{n_column})'\n",
        "    else:\n",
        "        print(\"유효하지 않은 값\")\n",
        "        break\n",
        "\n",
        "    wb = load_workbook(ti +\".\"+ lang)\n",
        "    ws = wb.active\n",
        "\n",
        "    ws[f\"{t_col}{n_column+1}\"] = value\n",
        "    wb.save(ti +\".\"+ lang)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHb8yTCt3IvF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "Ysjma9VbNFqX",
        "outputId": "03f9de28-64ea-44b8-a7d8-99f920ef9d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "생성할 파일 유형을 선택해주세요\n",
            " 1. PPT\n",
            " 2. Excel\n",
            " 3. Word \n",
            " 4. Source File \n",
            " 0. exit \n",
            "3\n",
            "파일 이름 with 파일 유형(.docx, .hwp, ...etc) \n",
            ".docx\n",
            "주제 분야 (과학, 인문 ..etc): 과학\n",
            "파일 목적( ex 과학혁명의 구조 보고서): 2022 과학 트랜드\n",
            "들어가야할 내용 (동기, 줄거리 , 결론 .. etc): 주제 선정 동기,  10가지 트렌드, 경향\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bb2f2df7b3a2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbig_cate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# 워드 class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m          \u001b[0mword_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbig_cate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# 코드 소스파일 class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-2ce552c3e250>\u001b[0m in \u001b[0;36mword_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"I'm in in the field of {role}. I'm going to write {title}. Write a report using according to {topic}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   response = client.completions.create(\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "flag_on = True\n",
        "while flag_on:\n",
        "    print(\"생성할 파일 유형을 선택해주세요\\n 1. PPT\\n 2. Excel\\n 3. Word \\n 4. Source File \\n 0. exit \")\n",
        "    big_cate = int(input())\n",
        "    if big_cate == 1:\n",
        "        # ppt class\n",
        "        a = 0\n",
        "    elif big_cate == 2:\n",
        "        # 엑셀 class\n",
        "        excel_file()\n",
        "    elif big_cate == 3:\n",
        "        # 워드 class\n",
        "         word_file()\n",
        "    elif big_cate == 4:\n",
        "        # 코드 소스파일 class\n",
        "        code_file()\n",
        "    elif big_cate == 0:\n",
        "        break\n",
        "    else:\n",
        "        print(\"잘못된 입력\")\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G-WfH8pxIc0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
